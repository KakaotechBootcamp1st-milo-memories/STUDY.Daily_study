# 서버 성능 기본 개념

## 성능 지표

- CPU 사용률
- 메모리 사용률
- 디스크 I/O
- 네트워크 대역폭
- 응답 시간
- 트랜잭션 처리율
- 에러율
- 업타임
- 다운타임

## 저하 원인

- 하드웨어 자원 한계
- 네트워크 병목
- 코드 최적화 문제

## 서버 성능 최적화의 중요성

- 사용자 만족도 향상
- 비용 절감
- 높은 가용성 및 신뢰성: 부하 분산과 자원 관리를 효율적으로 수행함으로 안정적인 운영 가능
- 경쟁력 강화

# 애플리케이션 레벨 최적화

## 1. 병목 지점 파악

- 모니터링 도구를  통해 앱의 업타임과 자원 사용량을 모니터링, 특정 기능 및 요청의 응답 시간 확인
- CPU 사용량 높음: 특정 코드 블록에서 CPU가 지나치게 많이 사용되는 경우 최적화 필요
- 메모리 누수: 메모리 사용량이 지속적으로 증가하는지 확인
- I/O 병목: 데이터 베이스 쿼리가 너무 많거나 디스크 I/O가 높은 경우 데이터 액세스를 최적화하거나 캐싱 고려

## 2. 코드 최적화

- 알고리즘 변경
- 반복문 최적화
- 메모리 관리
- 비동기 처리: I/O 작업이나 네트워크 호출과 같은 블로킹 작업을 비동기적으로 처리하여 CPU 자원을 효율적으로 활용
- 병렬 처리: 여러 작업을 동시에 처리하여 전체 실행 시간을 단축하고 CPU 코어를 최대한 활용

> 알고리즘 성능 표기법
- Big-O: 최악의 경우 시간 복잡도
- Omega: 최선의 경우 시간 복잡도
- Theta: 평균 시간 복잡도
> 

### GC(Garbage Collector)

더 이상 사용되지 않는 객체를 자동으로 제거하여 메모리를 관리

- 주요 단계
    - Mark: 사용 중인 객체와 사용되지 않는 객체 식별
    - Sweep: 사용되지 않는 객체를 제거
    - Compact: 남은 객체들을 모아 메모리 단편화 방지(선택적)

Serial, Parallel, CMS, G1, ZGC, Mark-and-Sweep 등 다양한 GC 알고리즘이 있음

Java9+에서는 G1 알고리즘이 사용되고 Node.js에서는 Orinoco 알고리즘이 사용됨

### 메모리 관리

- 객체 및 배열 사용 최적화
    - 객체 및 배열 초기화: 불필요한 미리 초기화나 너무 큰 배열을 만드는 것은 메모리 낭비
    - 객체 및 배열 사용후 메모리 해제: 더이상 사용하지 않는 객체나 배열은 null로 할당하여 메모리가 해제될 수 있도록 한다.
- 클로저 사용 최적화
    - 자바스크립트에서 클로저는 외부 함수의 변수를 계속 참조할 수 있어 메모리 누수가 발생할 수 있음. 필요한 경우에만 사용하고 불필요한 참조를 해제
    - 자바에서는 내부 클래스를 사용할 때 외부 클래스의 참조를 가지게 되는 경우가 있는데 이 경우에도 필요없는 경우에는 참조를 해제하여 메모리 누수 방지
    
    ```jsx
    // 자바 클래스 예시
    public class OuterClass {
        private Object bigObject = new Object();
    
        public Runnable createInnerInstance() {
            return new Runnable() {
                @Override
                public void run() {
                    // bigObject 사용
                }
            };
        }
    }
    
    // 사용 예제
    OuterClass outer = new OuterClass();
    Runnable innerInstance = outer.createInnerInstance();
    // innerInstance 사용 후
    innerInstance = null; // 참조 해제
    ```
    

### 비동기 처리

<img width="721" alt="image" src="https://github.com/user-attachments/assets/90228507-c866-4f7b-94e8-56874fa71d7f">

- 작업을 순차적으로 처리하는 것이 아닌 작업의 완료를 기다리지 않고 다음 작업을 동시에 수행
- I/O 작업을 효율적으로 처리하여 doqd 응답성을 향상시키고 자원을 효율적으로 관리 가능
- 필요성
    - 블로킹 방지: 동기적으로 작업을 처리하면 하나의 느린 작업으로 인해 모든 스레드가 대기 상태에 빠질 수 있지만 비동기로 처리하면 앱 응답성을 높일 수 있음
    - 성능 개선
- 자바 스크립트

```jsx
function fetchData() {
    return new Promise((resolve, reject) => {
        setTimeout(() => {
            resolve("Data retrieved");
        }, 1000);
    });
}

fetchData()
    .then((result) => {
        console.log(result); // 'Data retrieved'
    })
    .catch((error) => {
        console.error(error);
    });
```

- JAVA

```jsx
import java.util.concurrent.*;

public class ExecutorServiceExample {

    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(1);
        Future<String> future = executor.submit(() -> {
            Thread.sleep(1000); // 작업 시뮬레이션을 위해 1초 대기
            return "Data from async operation";
        });

        try {
            String result = future.get();
            System.out.println("Data retrieved: " + result);
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        }

        executor.shutdown();
    }
}
```

### 비동기 처리 최적화 방법

- 병렬 실행: 독립적인 여러 비동기 작업을 동시에 실행
    - 자바스크립트: promise.all() 또는 promise.allSettled()
    - 자바: completableFuture.allOf() 또는 병렬 스트림 사용
    - 전체 시간이 단축되고 리소스 활용도가 향상되지만 너무 많은 동시 실행은 시스템에 부하를 줌
- 비동기 작업 체이닝 최적화: 연속된 비동기 작업들을 효율적으로 연결하여 처리
- 결과 캐싱: 비용이 많이 드는 비동기 작업의 결과를 캐싱
    - 앱 메모리에 캐싱(예: Map 객체)
    - 외부 캐시 시스템 사용(예: Redis)
    - 반복적인 비동기 작업 시간을 단축하여 서버 부하 감소
    - 캐시 무효화 전략이 필요하고 앱 및 외부 시스템의 메모리 사용량 고려
- 스트림 처리: 대용량 데이터를 작은 청크 단위로 처리
    - 자바스크립트: 이터레이터, 제너레이터 함수 사용
    - 자바: [java.util.stream](http://java.util.stream) API 활용
    - 메모리 효율성 향상, 대용량 데이터 처리 가능
    - 효율적으로 데이터를 처리하기 위한 스트림 처리 로직 설계

## 3. 앱 성능 재측정하기

- 코드 최적화 후에는 성능 측정 도구를 통해 성능 재측정
- 이전 측정 결과와 비교하여 코드 최적화가 어떤 영향을 미쳤는지 분석

# 서버 레벨 최적화

## 서버 설정 최적화(Nginx, Apache 등)

- 버퍼 및 연결 설정: 클라이언트 요청을 처리하는 버퍼 크기와 동시 연결 수를 조정하여 서버 응답 속도를 최적화
- Keep-Alive 설정: Keep-Alive를 적절히 활용하여 여러 요청을 하나의 TCP 연결로 관리하여 네트워크 지연을 줄임
- 캐싱 설정: 정적 파일 캐싱을 통해 반복적인 파일 요청에 대한 서버 부하를 감소시키고 응답 속도를 높임
- 압축 설정: Gzip 등의 압축 알고리즘을 사용하여 전송 데이터를 압축하여 대역폭을 절감하고 네트워크 성능 개선
- 요청 및 응답 버퍼 크기 조정: 버퍼 크기가 너무 작으면 디스크 I/O가 증가하고 너무 크면 메모리 낭비
- 연결 타임아웃 조정: 연결 유지 시간이 너무 짧으면 불필요한 재연결이 자주 발생하고 너무 길면 유휴 연결로 인해 리소스 낭비

## 로드 밸런싱

<img width="721" alt="image" src="https://github.com/user-attachments/assets/c06e9736-0126-4fa7-8298-a0abd27beef3">

여러 서버나 네트워크 장치에 가해지는 부하를 분산

하드웨어 및 소프트웨어 로드 밸런싱을 통해 여러 서버 간 트래픽을 분산하여 서비스의 가용성과 성능 향상

스티키 세션을 활용하여 동일한 사용자 요청이 항상 같은 서버로 전달되도록 유지하여 세션 관리의 복잡성을 줄임

### 주요 목표

- 부하 분산
- 고가용성: 하나 이상의 서버가 다운되어도 다른 서버가 요청을 처리하여 서비스 중단 최소화
- 응답 시간 개선

### 로드 밸런서 종류

- 하드웨어 로드 밸런서
    - 하드웨어 장비를 사용하여 로드 밸런싱 수행, 높은 처리량과 성능을 제공하지만 비용이 높고 확장성이 제한될 수 있음
- 소프트웨어 로드 밸런서
    - 서버 프로그램을 사용, 가상 머신, 컨테이너, 클라우드 인스턴스 등에서 실행할 수 있어 확장성이 좋음
    - Nginx, Apache 등을 통해 수행 가능
- DNS 기반 로드 밸런서
    - DNS 서버에서 클라이언트 요청을 여러 서버 IP 주소로 매핑하여 부하 분산
    - 간단하고 저렴하지만 실시간으로 서버 상태를 감지하지 못하고 부하 분산을 정교하게 조정할 수 없음

### Nginx에서 로드밸런싱 설정하기

```jsx
upstream servers {
    server localhost:8000;
    server localhost:8001;
    server localhost:8002;

    # 로드 밸런싱 방식 설정 (옵션)
    # least_conn: 연결 수가 가장 적은 서버 선택
    # ip_hash: 클라이언트 IP 주소에 따라 항상 같은 서버 선택
    # 등 다양한 옵션이 있음
}

server {
    listen 80;

    location / {
        proxy_pass http://servers;
    }
}
```

1. Upstream 블록 정의하기: Upstream 블록을 사용하여 백엔드 서버 그룹 정의, 이 그룹에는 로드 밸런싱이 적용될 서버들의 주소와 포트 포함
2. 로드 밸런싱 옵션 추가하기: 정의한 Upstream 블록에 로드 밸런싱 알고리즘과 기타 옵션 추가 가능, 기본적으로 Nginx는 Round Robin 방식을 사용

### 설정 상세 설명

- Upstream 블록: servers upstream 블록 내에서 localhost를 사용하여 로컬 서버에 대한 서버 그룹 정의
- proxy_pass 설정: location/ 블록 내에서 proxy_pass 지시어를 사용하여 실제 요청을 처리할 서버 그룹 지정

## 서버 컴퓨팅 리소스 관리

- CPU 관리 및 최적화: CPU 사용률을 모니터링하고 다중 코어를 효율적으로 활용하여 작업 처리 능력 최대화
    - 멀티스레딩 및 멀티 프로세스: 다중 스레드 및 프로세스를 이용하여 병렬 처리를 촉진하고 CPU 자원을 최대한 활용
    - 최적화된 코드 실행: JIT 컴파일러와 같은 기술을 사용하여 CPU가 더 빠르게 코드를 실행할 수 있도록 최적화
- 메모리 관리: 메모리 사용량 모니터링, 가비지 컬렉션 조정으로 메모리 누수 방지
    - 힙 및 스택 최적화: 메모리 할당 및 해제를 최적화하여 메모리 관리 오버헤드를 줄이고 성능 향상
- 디스크 I/O 관리: 디스크 접근 속도를 향상시키기 위해 SSD 등 고성능 스토리지를 사용하거나 RAID 설정을 최적화
    - 캐싱 전략: 서버와 데이터베이스 사이 I/O 비용을 줄이기 위해 적절한 데이터 캐싱 전략을 도입하여 데이터 접근 속도를 높임

## 데이터베이스 최적화

- 인덱스 최적화
    - 적절한 인덱스를 사용하여 데이터베이스 질의 속도를 높임
    - 자주 사용되는 필드에 인덱스를 추가하여 검색 및 정렬 작업 최적화
- 쿼리 최적화
    - 쿼리 튜닝: 비효율적인 쿼리를 개선하고 조인 및 서브쿼리를 최적화하여 데이터베이스 부하를 줄임
- 버퍼 풀 및 캐시 관리
    - 버퍼 풀 크기 조정: 데이터베이스 캐시 메모리를 적절히 할당하여 자주 액세스되는 데이터를 메모리에 유지
    - 쿼리 캐싱: 동일한 쿼리의 결과를 캐시하여 데이터베이스 부하를 줄이고 응답 시간 단축
- 분할 및 파티셔닝
    - 대용량 테이블을 파티션화하여 데이터를 물리적으로 분리하고 질의 속도 향상
    - 시간 기반 파티셔닝을 사용하여 데이터를 시간별로 분할하여 데이터 유지 관리 용이

# 클라우드 환경 최적화

## 스케일 아웃과 스케일 업

### 스케일 아웃(Scale Out)

기존 시스템에 새로운 인스턴스를 추가하거나 기존 인스턴스를 복제하여 트래픽 분산

트래픽이 증가하거나 서비스 부하를 분산시키기 위해 사용

장점

- 확장성: 트래픽 증가에 따라 필요한 만큼의 자원 추가 가능
- 고가용성: 여러 인스턴스를 통해 장애 발생 시 서비스 중단 최소화

**→ 스케일 아웃은 수평적 확장으로 서버 인스턴스를 여러 대로 늘려 트래픽을 분산**

### 스케일 업(Scale Up)

기존 인스턴스의 하드웨어 컴퓨팅 사양을 증가시켜 단일 인스턴스의 성능 향상

보통 더 높은 사양의 인스턴스로 업그레이드하거나 가상 머신 인스턴스의 CPU 및 메모리를 추가 할당하여 성능 향상

단일 인스턴스에서 더 많은 처리 능력이 필요할 때 사용##

장점

- 성능 향상
- 운영 효율

→ 스케일 업은 수직적 확장으로 단일 인스턴스 리소스를 증가시켜 성능을 향상

## 오토 스케일링

클라우드 환경에서 자동으로 서버 인스턴스 수를 조정하여 트래픽 변동에 효율적으로 대응

주로 웹 앱과 같은 서비스에서 사용되며 사용량에 따라 자동으로 인스턴스를 추가하거나 제거하여 서비스 가용성을 유지하고 비용을 절감(Scale Out)

### 동작 원리

- 트리거 설정: 설정된 트리거를 기반으로 동작, 주로 CPU 사용률, 메모리 사용량, 네트워크 트래픽 등의 지표가 사용됨
    - 예: CPU 사용률이 70%를 넘으면 자동으로 인스턴스를 추가하고 CPU 사용률이 일정 기준 이하로 내려가면 인스턴스를 줄임
- 스케일링 액션: 트리거가 발생하면 오토 스케일링 서비스는 다음과 같은 액션 수행
    - 자동 스케일 아웃: 추가 인스턴스를 시작하여 트래픽 수요를 맞춤
    - 자동 스케일 인: 트래픽이 감소하면 필요하지 않은 인스턴스 자동 종료
- 스케일링 그룹: 인스턴스를 관리하는 단위로 하나 이상의 서버 인스턴스 포함, 스케일링 그룹은 동일한 앱 또는 서비스에 속한 인스턴스들을 관리하며 고가용성을 보장하고 로드 밸런싱 수행

### 장점

- 자원 최적화
- 가용성 향상
- 비용 절감

### 주의 사항

- 트리거 설정: 너무 높은 트리거 설정은 초과 비용 발생, 너무 낮은 설정은 성능 저하 초래
- 테스트: 예기치 않은 스케일링 액션을 방지하기 위해 경험과 데이터를 기반으로 설정 필요
- 적절한 테스트와 모니터링을 통해 클라우드 서비스 비용을 최적화해야함

## 컨테이너화 및 오케스트레이션

<img width="721" alt="image" src="https://github.com/user-attachments/assets/9d2ac3b7-6a0b-4a2e-bcd7-26675c87ab63">

- 컨테이너는 앱과 그 의존성을 함께 묶어 격리된 환경에서 실행할 수 있게 하는 가상화 기술

### 주요 구성 요소

- 이미지
    - 컨테이너 실행에 필요한 파일 시스템과 앱 코드를 포함한 불변 패키지
    - 앱의 실행 환경과 의존성 포함
- 컨테이너
    - 이미지를 실행한 상태로 앱이 실행되는 격리된 환경
    - 컨테이너는 일회성으로 실행되며 종료되면 상태가 유지되지 않음
- 레지스트리
    - 이미지를 저장하고 배포하는 저장소
- Dockerfile
    - 이미지를 생성하기 위한 설정 파일
    - 명령어를 통해 이미지 빌드 과정 정의

### 컨테이너 주요 특징

<img width="721" alt="image" src="https://github.com/user-attachments/assets/4c3ee078-b633-4853-96ed-53beb697a30c">

- 격리성: 각 컨테이너는 별도의 프로세스와 파일 시스템을 사용하여 독립된 환경 제공, 이를 통해 앱 간 간섭 최소화
- 이식성: 컨테이너는 운영체제 수준에서 가상화되므로 동일한 컨테이너 이미지를 어디서나 실행 가능
- 경량성: 컨테이너는 호스트 운영 체제의 커널을 공유하므로 전통적인 가상 머신보다는 훨씬 가벼우며 빠르게 시작 가능
- 신속한 배포: 컨테이너는 빠르게 생성, 삭제, 배포할 수 있으며 앱의 지속적 배포(CD)와 통합(CI)에 적합

```jsx
# 베이스 이미지로 Full Ubuntu 이미지 사용
FROM ubuntu:latest

# 모든 소스 파일을 루트 디렉터리에 복사
COPY . /app

# 필요 없는 패키지도 함께 설치
RUN apt-get update && apt-get install -y python3 python3-pip nodejs npm

# 작업 디렉터리 설정
WORKDIR /app

# 애플리케이션 의존성 설치
RUN pip3 install -r requirements.txt
RUN npm install

# 애플리케이션 실행 명령
CMD ["python3", "app.py"]
```

### 컨테이너 오케스트레이션

여러 컨테이너의 배포, 관리, 확장, 네트워킹, 로깅 등을 자동화하는 프로세스

수많은 컨테이너가 복잡하게 얽혀있는 앱 환경에서 필수적인 도구로 주로 Kubernetes와 Docker Swarm과 같은 플랫폼이 사용됨

- 주요 기능
    - 자동 배포 및 복구: 컨테이너화된 앱을 자동으로 배포하고 장애 발생 시 자동 복구
    - 확장 및 축소: 수요에 따라 컨테이너 인스턴스를 자동으로 확장(Scale Out)하거나 축소(Scale In)함
    - 리소스 할당: CPU, 메모리, 스토리지 등 자원을 컨테이너에 효율적으로 할당하여 성능 최적화
    - 로드 밸런싱: 트래픽을 여러 컨테이너 인스턴스로 분산시켜 앱 가용성과 성능 향상

### Kubernetes

가장 널리 사용되는 컨테이너 오케스트레이션 도구로 google에서 개발한 오픈소스

자동 배포, 확장, 복구, 로드 밸런싱, 비밀 관리, 네임스페이스로 자원 격리 등의 다양한 기능 제공

- 구성 요소
    - 마스터 노드: 클러스터 관리
    - 워커 노드: 실제 앱 컨테이너가 실행되는 노드

### Kubernetes 최적화

- 클러스터 설정 최적화: 클러스터 노드 수와 크기를 적절히 설정하여 워크로드 분산
- 오토 스케일링: HPA를 사용하여 트래픽 증가 시 자동으로 파드를 확장하고 트래픽 감소 시 축소
- 리소스 요청 및 제한 설정: 각 파드의 CPU와 메모리 요청 및 제한을 설정하여 자원 분배 최적화
- 네임스페이스 활용: 네임스페이스를 통해 리소스를 격리하고 관리하여 성능 최적화
- 네트워크 최적화: 네트워크 플러그인을 사용하여 네트워크 성능을 최적화하고 서비스 간 트래픽 최적화

# CDN(Content Delivery Network)

전 세계적으로 사용자에게 웹 콘텐츠를 빠르게 전송하는 서비스, 주로 정적 파일을 효율적으로 제공하고 대규모 트래픽 처리와 성능 최적화를 위해 사용

### 주요 구성 요소

- Edge Servers: CDN의 핵심 구성 요소로 전 세계 여러 지역에 분포된 서버, 이 서버들은 콘텐츠를 캐싱하고 사용자에게 제공
- Origin Server: 원본 서버는 CDN에 의해 캐싱되는 콘텐츠의 출처가 되는 서버, CDN이 원본 서버에서 콘텐츠를 가져와 캐싱
- DNS 서비스: CDN은 DNS를 통해 사용자 위치를 식별하고 가장 가까운 CDN 서버로 리디렉션

### 주요 기능과 원리

- 캐싱: CDN은 전 세계에 분산된 서버 네트워크를 통해 콘텐츠를 캐싱, 원본 서버에 직접 접근 횟수를 줄이고 사용자 요청에 빠르게 응답 가능
- 근접성 최적화: CDN 서버는 사용자에게 더 가까운 위치에 배치되어있어 물리적 거리에 따른 지연을 줄이고 더 빠른 콘텐츠 전송을 가능하게 함
- 부하 분산: 트래픽을 여러 CDN 서버로 분산
- 보안: DDoS 공격으로부터 보호할 수 있는 기능을 제공할 수 있고 SSL 인증서를 통한 암호화 서비스도 제공 가능
